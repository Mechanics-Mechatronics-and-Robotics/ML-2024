{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single sample from the generated dataset:\n",
      "['a', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set seed such that we always get the same dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_dataset(num_sequences=100):\n",
    "    \"\"\"\n",
    "    Generates a number of sequences as our dataset.\n",
    "    \n",
    "    Args:\n",
    "     `num_sequences`: the number of sequences to be generated.\n",
    "     \n",
    "    Returns a list of sequences.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    for _ in range(num_sequences): \n",
    "        num_tokens = np.random.randint(1, 10)\n",
    "        sample = ['a'] * num_tokens + ['b'] * num_tokens + ['EOS']\n",
    "        samples.append(sample)\n",
    "        \n",
    "    return samples\n",
    "\n",
    "\n",
    "sequences = generate_dataset()\n",
    "\n",
    "print('A single sample from the generated dataset:')\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 100 sentences and 4 unique tokens in our dataset (including UNK).\n",
      "\n",
      "The index of 'b' is 1\n",
      "The word corresponding to index 1 is 'b'\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def sequences_to_dicts(sequences):\n",
    "    \"\"\"\n",
    "    Creates word_to_idx and idx_to_word dictionaries for a list of sequences.\n",
    "    \"\"\"\n",
    "    # A bit of Python-magic to flatten a nested list\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    \n",
    "    # Flatten the dataset\n",
    "    all_words = flatten(sequences)\n",
    "    \n",
    "    # Count number of word occurences\n",
    "    word_count = defaultdict(int)\n",
    "    for word in flatten(sequences):\n",
    "        word_count[word] += 1\n",
    "\n",
    "    # Sort by frequency\n",
    "    word_count = sorted(list(word_count.items()), key=lambda l: -l[1])\n",
    "\n",
    "    # Create a list of all unique words\n",
    "    unique_words = [item[0] for item in word_count]\n",
    "    \n",
    "    # Add UNK token to list of words\n",
    "    unique_words.append('UNK')\n",
    "\n",
    "    # Count number of sequences and number of unique words\n",
    "    num_sentences, vocab_size = len(sequences), len(unique_words)\n",
    "\n",
    "    # Create dictionaries so that we can go from word to index and back\n",
    "    # If a word is not in our vocabulary, we assign it to token 'UNK'\n",
    "    word_to_idx = defaultdict(lambda: num_words)\n",
    "    idx_to_word = defaultdict(lambda: 'UNK')\n",
    "\n",
    "    # Fill dictionaries\n",
    "    for idx, word in enumerate(unique_words):\n",
    "        word_to_idx[word] = idx\n",
    "        idx_to_word[idx] = word\n",
    "\n",
    "    return word_to_idx, idx_to_word, num_sentences, vocab_size\n",
    "\n",
    "\n",
    "word_to_idx, idx_to_word, num_sequences, vocab_size = sequences_to_dicts(sequences)\n",
    "\n",
    "print(f'We have {num_sequences} sentences and {len(word_to_idx)} unique tokens in our dataset (including UNK).\\n')\n",
    "print('The index of \\'b\\' is', word_to_idx['b'])\n",
    "print(f'The word corresponding to index 1 is \\'{idx_to_word[1]}\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 80 samples in the training set.\n",
      "We have 10 samples in the validation set.\n",
      "We have 10 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve inputs and targets at the given index\n",
    "        X = self.inputs[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "def create_datasets(sequences, dataset_class, p_train=0.8, p_val=0.1, p_test=0.1):\n",
    "    # Define partition sizes\n",
    "    num_train = int(len(sequences)*p_train)\n",
    "    num_val = int(len(sequences)*p_val)\n",
    "    num_test = int(len(sequences)*p_test)\n",
    "\n",
    "    # Split sequences into partitions\n",
    "    sequences_train = sequences[:num_train]\n",
    "    sequences_val = sequences[num_train:num_train+num_val]\n",
    "    sequences_test = sequences[-num_test:]\n",
    "\n",
    "    def get_inputs_targets_from_sequences(sequences):\n",
    "        # Define empty lists\n",
    "        inputs, targets = [], []\n",
    "        \n",
    "        # Append inputs and targets s.t. both lists contain L-1 words of a sentence of length L\n",
    "        # but targets are shifted right by one so that we can predict the next word\n",
    "        for sequence in sequences:\n",
    "            inputs.append(sequence[:-1])\n",
    "            targets.append(sequence[1:])\n",
    "            \n",
    "        return inputs, targets\n",
    "\n",
    "    # Get inputs and targets for each partition\n",
    "    inputs_train, targets_train = get_inputs_targets_from_sequences(sequences_train)\n",
    "    inputs_val, targets_val = get_inputs_targets_from_sequences(sequences_val)\n",
    "    inputs_test, targets_test = get_inputs_targets_from_sequences(sequences_test)\n",
    "\n",
    "    # Create datasets\n",
    "    training_set = dataset_class(inputs_train, targets_train)\n",
    "    validation_set = dataset_class(inputs_val, targets_val)\n",
    "    test_set = dataset_class(inputs_test, targets_test)\n",
    "\n",
    "    return training_set, validation_set, test_set\n",
    "    \n",
    "\n",
    "training_set, validation_set, test_set = create_datasets(sequences, Dataset)\n",
    "\n",
    "print(f'We have {len(training_set)} samples in the training set.')\n",
    "print(f'We have {len(validation_set)} samples in the validation set.')\n",
    "print(f'We have {len(test_set)} samples in the test set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our one-hot encoding of 'a' has shape (4,).\n",
      "Our one-hot encoding of 'a b' has shape (2, 4, 1).\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(idx, vocab_size):\n",
    "    \"\"\"\n",
    "    One-hot encodes a single word given its index and the size of the vocabulary.\n",
    "    \n",
    "    Args:\n",
    "     `idx`: the index of the given word\n",
    "     `vocab_size`: the size of the vocabulary\n",
    "    \n",
    "    Returns a 1-D numpy array of length `vocab_size`.\n",
    "    \"\"\"\n",
    "    # Initialize the encoded array\n",
    "    one_hot = np.zeros(vocab_size)\n",
    "    \n",
    "    # Set the appropriate element to one\n",
    "    one_hot[idx] = 1.0\n",
    "\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def one_hot_encode_sequence(sequence, vocab_size):\n",
    "    \"\"\"\n",
    "    One-hot encodes a sequence of words given a fixed vocabulary size.\n",
    "    \n",
    "    Args:\n",
    "     `sentence`: a list of words to encode\n",
    "     `vocab_size`: the size of the vocabulary\n",
    "     \n",
    "    Returns a 3-D numpy array of shape (num words, vocab size, 1).\n",
    "    \"\"\"\n",
    "    # Encode each word in the sentence\n",
    "    encoding = np.array([one_hot_encode(word_to_idx[word], vocab_size) for word in sequence])\n",
    "\n",
    "    # Reshape encoding s.t. it has shape (num words, vocab size, 1)\n",
    "    encoding = encoding.reshape(encoding.shape[0], encoding.shape[1], 1)\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "\n",
    "test_word = one_hot_encode(word_to_idx['a'], vocab_size)\n",
    "print(f'Our one-hot encoding of \\'a\\' has shape {test_word.shape}.')\n",
    "\n",
    "test_sentence = one_hot_encode_sequence(['a', 'b'], vocab_size)\n",
    "print(f'Our one-hot encoding of \\'a b\\' has shape {test_sentence.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50 # Number of dimensions in the hidden state\n",
    "vocab_size  = len(word_to_idx) # Size of the vocabulary used\n",
    "\n",
    "def init_orthogonal(param):\n",
    "    \"\"\"\n",
    "    Initializes weight parameters orthogonally.\n",
    "    \n",
    "    Refer to this paper for an explanation of this initialization:\n",
    "    https://arxiv.org/abs/1312.6120\n",
    "    \"\"\"\n",
    "    if param.ndim < 2:\n",
    "        raise ValueError(\"Only parameters with 2 or more dimensions are supported.\")\n",
    "\n",
    "    rows, cols = param.shape\n",
    "    \n",
    "    new_param = np.random.randn(rows, cols)\n",
    "    \n",
    "    if rows < cols:\n",
    "        new_param = new_param.T\n",
    "    \n",
    "    # Compute QR factorization\n",
    "    q, r = np.linalg.qr(new_param)\n",
    "    \n",
    "    # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n",
    "    d = np.diag(r, 0)\n",
    "    ph = np.sign(d)\n",
    "    q *= ph\n",
    "\n",
    "    if rows < cols:\n",
    "        q = q.T\n",
    "    \n",
    "    new_param = q\n",
    "    \n",
    "    return new_param\n",
    "\n",
    "def init_rnn(hidden_size, vocab_size):\n",
    "    \"\"\"\n",
    "    Initializes our recurrent neural network.\n",
    "    \n",
    "    Args:\n",
    "     `hidden_size`: the dimensions of the hidden state\n",
    "     `vocab_size`: the dimensions of our vocabulary\n",
    "    \"\"\"\n",
    "    # Weight matrix (input to hidden state)\n",
    "    # YOUR CODE HERE!\n",
    "    U = np.zeros((hidden_size, vocab_size))\n",
    "\n",
    "    # Weight matrix (recurrent computation)\n",
    "    # YOUR CODE HERE!\n",
    "    V = np.zeros((hidden_size, hidden_size))\n",
    "\n",
    "    # Weight matrix (hidden state to output)\n",
    "    # YOUR CODE HERE!\n",
    "    W = np.zeros((vocab_size, hidden_size))\n",
    "\n",
    "    # Bias (hidden state)\n",
    "    # YOUR CODE HERE!\n",
    "    b_hidden = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Bias (output)\n",
    "    # YOUR CODE HERE!\n",
    "    b_out = np.zeros((vocab_size, 1))\n",
    "    \n",
    "    # Initialize weights\n",
    "    U = init_orthogonal(U)\n",
    "    V = init_orthogonal(V)\n",
    "    W = init_orthogonal(W)\n",
    "    \n",
    "    # Return parameters as a tuple\n",
    "    return U, V, W, b_hidden, b_out\n",
    "\n",
    "\n",
    "params = init_rnn(hidden_size=hidden_size, vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the element-wise sigmoid activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = 1 / (1 + np.exp(-x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        return f * (1 - f)\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the element-wise tanh activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = (np.exp(x_safe)-np.exp(-x_safe))/(np.exp(x_safe)+np.exp(-x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        return 1-f**2\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the softmax for an array x.\n",
    "    \n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = np.exp(x_safe) / np.sum(np.exp(x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        pass # We will not need this one\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence:\n",
      "['a', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b']\n",
      "\n",
      "Target sequence:\n",
      "['a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'EOS']\n",
      "\n",
      "Predicted sequence:\n",
      "['UNK', 'UNK', 'UNK', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'EOS', 'EOS', 'b']\n"
     ]
    }
   ],
   "source": [
    "def forward_pass(inputs, hidden_state, params):\n",
    "    \"\"\"\n",
    "    Computes the forward pass of a vanilla RNN.\n",
    "    \n",
    "    Args:\n",
    "     `inputs`: sequence of inputs to be processed\n",
    "     `hidden_state`: an already initialized hidden state\n",
    "     `params`: the parameters of the RNN\n",
    "    \"\"\"\n",
    "    # First we unpack our parameters\n",
    "    U, V, W, b_hidden, b_out = params\n",
    "    \n",
    "    # Create a list to store outputs and hidden states\n",
    "    outputs, hidden_states = [], []\n",
    "    \n",
    "    # For each element in input sequence\n",
    "    for t in range(len(inputs)):\n",
    "\n",
    "        # Compute new hidden state\n",
    "        # YOUR CODE HERE!\n",
    "        hidden_state = tanh(np.dot(U, inputs[t]) + np.dot(V, hidden_state) + b_hidden)\n",
    "\n",
    "        # Compute output\n",
    "        # YOUR CODE HERE!\n",
    "        out = softmax(np.dot(W, hidden_state) + b_out)\n",
    "        \n",
    "        # Save results and continue\n",
    "        outputs.append(out)\n",
    "        hidden_states.append(hidden_state.copy())\n",
    "    \n",
    "    return outputs, hidden_states\n",
    "\n",
    "\n",
    "# Get first sequence in training set\n",
    "test_input_sequence, test_target_sequence = training_set[0]\n",
    "\n",
    "# One-hot encode input and target sequence\n",
    "test_input = one_hot_encode_sequence(test_input_sequence, vocab_size)\n",
    "test_target = one_hot_encode_sequence(test_target_sequence, vocab_size)\n",
    "\n",
    "# Initialize hidden state as zeros\n",
    "hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "# Now let's try out our new function\n",
    "outputs, hidden_states = forward_pass(test_input, hidden_state, params)\n",
    "\n",
    "print('Input sequence:')\n",
    "print(test_input_sequence)\n",
    "\n",
    "print('\\nTarget sequence:')\n",
    "print(test_target_sequence)\n",
    "\n",
    "print('\\nPredicted sequence:')\n",
    "print([idx_to_word[np.argmax(output)] for output in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient_norm(grads, max_norm=0.25):\n",
    "    \"\"\"\n",
    "    Clips gradients to have a maximum norm of `max_norm`.\n",
    "    This is to prevent the exploding gradients problem.\n",
    "    \"\"\" \n",
    "    # Set the maximum of the norm to be of type float\n",
    "    max_norm = float(max_norm)\n",
    "    total_norm = 0\n",
    "    \n",
    "    # Calculate the L2 norm squared for each gradient and add them to the total norm\n",
    "    for grad in grads:\n",
    "        grad_norm = np.sum(np.power(grad, 2))\n",
    "        total_norm += grad_norm\n",
    "    \n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    # Calculate clipping coeficient\n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    \n",
    "    # If the total norm is larger than the maximum allowable norm, then clip the gradient\n",
    "    if clip_coef < 1:\n",
    "        for grad in grads:\n",
    "            grad *= clip_coef\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get a loss of:\n",
      "4.553408581307237\n"
     ]
    }
   ],
   "source": [
    "def backward_pass(inputs, outputs, hidden_states, targets, params):\n",
    "    \"\"\"\n",
    "    Computes the backward pass of a vanilla RNN.\n",
    "    \n",
    "    Args:\n",
    "     `inputs`: sequence of inputs to be processed\n",
    "     `outputs`: sequence of outputs from the forward pass\n",
    "     `hidden_states`: sequence of hidden_states from the forward pass\n",
    "     `targets`: sequence of targets\n",
    "     `params`: the parameters of the RNN\n",
    "    \"\"\"\n",
    "    # First we unpack our parameters\n",
    "    U, V, W, b_hidden, b_out = params\n",
    "    \n",
    "    # Initialize gradients as zero\n",
    "    d_U, d_V, d_W = np.zeros_like(U), np.zeros_like(V), np.zeros_like(W)\n",
    "    d_b_hidden, d_b_out = np.zeros_like(b_hidden), np.zeros_like(b_out)\n",
    "    \n",
    "    # Keep track of hidden state derivative and loss\n",
    "    d_h_next = np.zeros_like(hidden_states[0])\n",
    "    loss = 0\n",
    "    \n",
    "    # For each element in output sequence\n",
    "    # NB: We iterate backwards s.t. t = N, N-1, ... 1, 0\n",
    "    for t in reversed(range(len(outputs))):\n",
    "\n",
    "        # Compute cross-entropy loss (as a scalar)\n",
    "        # YOUR CODE HERE!\n",
    "        loss += -np.mean(np.log(outputs[t]+1e-12) * targets[t])\n",
    "        \n",
    "        # Backpropagate into output (derivative of cross-entropy)\n",
    "        # if you're confused about this step, see this link for an explanation:\n",
    "        # http://cs231n.github.io/neural-networks-case-study/#grad\n",
    "        # YOUR CODE HERE!\n",
    "        d_o = outputs[t].copy()\n",
    "        d_o[np.argmax(targets[t])] -= 1\n",
    "        \n",
    "        # Backpropagate into W\n",
    "        # YOUR CODE HERE!\n",
    "        d_W += np.dot(d_o, hidden_states[t].T)\n",
    "        d_b_out += d_o\n",
    "        \n",
    "        # Backpropagate into h\n",
    "        # YOUR CODE HERE!\n",
    "        d_h = np.dot(W.T, d_o) + d_h_next\n",
    "        \n",
    "        # Backpropagate through non-linearity\n",
    "        d_f = tanh(hidden_states[t], derivative=True) * d_h\n",
    "        d_b_hidden += d_f\n",
    "        \n",
    "        # Backpropagate into U\n",
    "        # YOUR CODE HERE!\n",
    "        d_U += np.dot(d_f, inputs[t].T)\n",
    "        \n",
    "        # Backpropagate into V\n",
    "        # YOUR CODE HERE!\n",
    "        d_V += np.dot(d_f, hidden_states[t-1].T)\n",
    "        d_h_next = np.dot(V.T, d_f)\n",
    "    \n",
    "    # Pack gradients\n",
    "    grads = d_U, d_V, d_W, d_b_hidden, d_b_out    \n",
    "    \n",
    "    # Clip gradients\n",
    "    grads = clip_gradient_norm(grads)\n",
    "    \n",
    "    return loss, grads\n",
    "\n",
    "\n",
    "loss, grads = backward_pass(test_input, outputs, hidden_states, test_target, params)\n",
    "\n",
    "print('We get a loss of:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, lr=1e-3):\n",
    "    # Take a step\n",
    "    for param, grad in zip(params, grads):\n",
    "        param -= lr * grad\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 3.703043404000114, validation loss: 3.7253638510366778\n",
      "Epoch 100, training loss: 2.5482632393055744, validation loss: 2.565572023003429\n",
      "Epoch 200, training loss: 1.9880142333179642, validation loss: 2.0131189666321054\n",
      "Epoch 300, training loss: 1.7188008978786447, validation loss: 1.7539022584112005\n",
      "Epoch 400, training loss: 1.587911348787962, validation loss: 1.6303629072567307\n",
      "Epoch 500, training loss: 1.5075009671922135, validation loss: 1.5533692674689297\n",
      "Epoch 600, training loss: 1.4474347963188197, validation loss: 1.493726595811963\n",
      "Epoch 700, training loss: 1.3952514236497053, validation loss: 1.4396767069478493\n",
      "Epoch 800, training loss: 1.3423156600350297, validation loss: 1.383039185570785\n",
      "Epoch 900, training loss: 1.2773975256533352, validation loss: 1.313513470097898\n",
      "Input sentence:\n",
      "['a', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b']\n",
      "\n",
      "Target sequence:\n",
      "['a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'EOS']\n",
      "\n",
      "Predicted sequence:\n",
      "['a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'EOS']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABUEklEQVR4nO3dd3hUddrG8e8kIQ2S0EmQhLIgSC+hSSd0pSygyNJc26KA+NoQWRRFxLIolhXLqqioFAOKCEgNvUgJUkJRQFghdBJqQjLn/ePsTAohJGSSM5ncn+s6V5gzZ2aeOaK5/VWbYRgGIiIiIh7Cy+oCRERERFxJ4UZEREQ8isKNiIiIeBSFGxEREfEoCjciIiLiURRuRERExKMo3IiIiIhH8bG6gIJmt9s5duwYQUFB2Gw2q8sRERGRHDAMgwsXLlCxYkW8vLJvmyly4ebYsWOEh4dbXYaIiIjcgqNHj1KpUqVsryly4SYoKAgwb05wcLDF1YiIiEhOJCYmEh4e7vw9np0iF24cXVHBwcEKNyIiIoVMToaUaECxiIiIeBSFGxEREfEoCjciIiLiUYrcmBsREXEtu91OcnKy1WWIB/D19b3pNO+cULgREZFblpyczKFDh7Db7VaXIh7Ay8uLqlWr4uvrm6f3UbgREZFbYhgGx48fx9vbm/DwcJf8H7cUXY5Fdo8fP05ERESeFtpVuBERkVuSkpLC5cuXqVixIoGBgVaXIx6gXLlyHDt2jJSUFIoVK3bL76OYLSIityQ1NRUgz10IIg6Ov0uOv1u3SuFGRETyRPv0iau46u+Swo2IiIh4FIUbERER8SgKNyIiInnUvn17nnjiiRxff/jwYWw2G7GxsflWE0BMTAw2m43z58/n6+e4G82WcqGEBDh4EBo1sroSERHJys3GdAwbNozp06fn+n3nzp2bq9k94eHhHD9+nLJly+b6s+TmFG5cJDYWGjeGMmXg5EnQ+DoREfdz/Phx559nzZrFCy+8wL59+5znAgICMlx/7dq1HIWW0qVL56oOb29vQkNDc/UayTl1S7nIHXeAry+cPg3791tdjYiIBQwDLl2y5jCMHJUYGhrqPEJCQrDZbM7HV69epWTJksyePZv27dvj7+/PjBkzOHPmDAMHDqRSpUoEBgZSr149vv322wzvm7lbqkqVKrz66qs88MADBAUFERERwccff+x8PnO3lKP7aPny5URGRhIYGMidd96ZIXgBvPLKK5QvX56goCAeeughnnvuORo2bJirf0zR0dHUqVMHPz8/qlSpwpQpUzI8/8EHH1CjRg38/f2pUKEC/fv3dz733XffUa9ePQICAihTpgydOnXi0qVLufr8gqBw4yJ+ftCskbm3yrp1FhcjImKFy5ehRAlrjsuXXfY1xowZw+OPP05cXBxdu3bl6tWrNGnShAULFrBr1y4eeeQRhgwZwqZNm7J9nylTphAZGcn27dt57LHHePTRR9m7d2+2rxk3bhxTpkxhy5Yt+Pj48MADDzif+/rrr5k0aRKvv/46W7duJSIigmnTpuXqu23dupV7772X++67j507dzJhwgTGjx/v7IrbsmULjz/+OC+//DL79u1j8eLFtG3bFjBbvQYOHMgDDzxAXFwcMTEx9O3bFyOHwbJAGUVMQkKCARgJCQmufeNt24zneNUAw3jg73bXvreIiBu6cuWKsWfPHuPKlSvmiYsXDcNsQyn44+LFXNf/+eefGyEhIc7Hhw4dMgBj6tSpN31tjx49jKeeesr5uF27dsbo0aOdjytXrmwMHjzY+dhutxvly5c3pk2bluGztm/fbhiGYaxcudIAjGXLljlf89NPPxmA8/42b97cGDFiRIY6WrVqZTRo0OCGdTre99y5c4ZhGMbf/vY3o3PnzhmueeaZZ4zatWsbhmEY0dHRRnBwsJGYmHjde23dutUAjMOHD9/w8/Lqur9T6eTm97dablylTh1a+W4BYF2MdscVkSIoMBAuXrTmcOH2D5GRkRkep6amMmnSJOrXr0+ZMmUoUaIES5Ys4ciRI9m+T/369Z1/dnR/nTx5MsevCQsLA3C+Zt++fTRr1izD9Zkf30xcXBytWrXKcK5Vq1YcOHCA1NRUOnfuTOXKlalWrRpDhgzh66+/5vL/WsUaNGhAVFQU9erV45577uGTTz7h3Llzufr8gqJw4yq+vtzZ9BoA+w75ceqUxfWIiBQ0mw2KF7fmcOEsjuLFi2d4PGXKFN5++22effZZVqxYQWxsLF27diU5Ofv/kc08ENlms9109/T0r3HM7Er/msyzvYxcdgkZhpHtewQFBbFt2za+/fZbwsLCeOGFF2jQoAHnz5/H29ubpUuXsmjRImrXrs17771HzZo1OXToUK5qKAgKNy5Uun197mAPAOvXW1yMiIi4xJo1a+jduzeDBw+mQYMGVKtWjQMHDhR4HTVr1mTz5s0Zzm3ZsiVX71G7dm3Wrl2b4dz69eu5/fbb8fb2BsDHx4dOnTrxxhtv8Ouvv3L48GFWrFgBmOGqVatWvPTSS2zfvh1fX1/mzZuXh2+VPzQV3JVat6YV64ijNuvWQe/eVhckIiJ5Vb16daKjo1m/fj2lSpXirbfeIj4+njvuuKNA6xg1ahQPP/wwkZGR3HnnncyaNYtff/2VatWq5fg9nnrqKZo2bcrEiRMZMGAAGzZs4P333+eDDz4AYMGCBRw8eJC2bdtSqlQpFi5ciN1up2bNmmzatInly5fTpUsXypcvz6ZNmzh16lSB34ecULhxpZYtac1M/sPDrFuZDGinXBGRwm78+PEcOnSIrl27EhgYyCOPPEKfPn1ISEgo0DoGDRrEwYMHefrpp7l69Sr33nsv999//3WtOdlp3Lgxs2fP5oUXXmDixImEhYXx8ssvc//99wNQsmRJ5s6dy4QJE7h69So1atTg22+/pU6dOsTFxbF69WqmTp1KYmIilStXZsqUKXTv3j2fvvGtsxm57bAr5BITEwkJCSEhIYHg4GCXv/9vd/Skxt4f8fVJJeGCN/7+Lv8IERG3cPXqVQ4dOkTVqlXx13/sLNG5c2dCQ0P56quvrC7FJbL7O5Wb399quXGxv3SIoPzeE5xMqcDWrZBpULqIiMgtuXz5Mh9++CFdu3bF29ubb7/9lmXLlrF06VKrS3M7GlDsYrY25rgb0GJ+IiLiOjabjYULF9KmTRuaNGnCjz/+SHR0NJ06dbK6NLejlhtXa92aVkxlHn1ZG5PCs8/qFouISN4FBASwbNkyq8soFNRy42rh4bSq8DsA69fZc7rdiYiIiLiIwk0+aNw+GH+ucCbRl0x7nomIiEg+U7jJB75tW9AMc2qext2IiIgULIWb/NA63aDiNdkvtS0iIiKupXCTH+rUoVVgLKBNNEVERAqawk1+8PamZUvzj/v/8Ocmm8CKiEgh0759e5544gnn4ypVqjB16tRsX2Oz2fj+++/z/Nmuep/sTJgwgYYNG+brZ+QnhZt8UrpDA2qzG9AmmiIi7qJnz543XBdmw4YN2Gw2tm3bluv3/eWXX3jkkUfyWl4GNwoYx48fd8stD9yJwk1+ad2a1pg7r65do/ngIiLu4MEHH2TFihX88ccf1z332Wef0bBhQxo3bpzr9y1XrhyBgYGuKPGmQkND8fPzK5DPKqwUbvJL06a08d4AwJrlSRYXIyIiAHfffTfly5dn+vTpGc5fvnyZWbNm8eCDD3LmzBkGDhxIpUqVCAwMpF69enz77bfZvm/mbqkDBw7Qtm1b/P39qV27dpZbJIwZM4bbb7+dwMBAqlWrxvjx47l27RoA06dP56WXXmLHjh3YbDZsNpuz5szdUjt37qRjx44EBARQpkwZHnnkES5evOh8/v7776dPnz7861//IiwsjDJlyjBixAjnZ+WE3W7n5ZdfplKlSvj5+dGwYUMWL17sfD45OZmRI0cSFhaGv78/VapUYfLkyc7nJ0yYQEREBH5+flSsWJHHH388x599K7R8bn4JDKRd/XOwHbbu9OXCBQgKsrooEZH8Yxhw+bI1nx0YCDbbza/z8fFh6NChTJ8+nRdeeAHb/140Z84ckpOTGTRoEJcvX6ZJkyaMGTOG4OBgfvrpJ4YMGUK1atVo3rz5TT/DbrfTt29fypYty8aNG0lMTMwwPschKCiI6dOnU7FiRXbu3MnDDz9MUFAQzz77LAMGDGDXrl0sXrzYuSpxSEjIde9x+fJlunXrRosWLfjll184efIkDz30ECNHjswQ4FauXElYWBgrV67kt99+Y8CAATRs2JCHH3745jcNeOedd5gyZQofffQRjRo14rPPPqNXr17s3r2bGjVq8O677zJ//nxmz55NREQER48e5ejRowB89913vP3228ycOZM6deoQHx/Pjh07cvS5t8woYhISEgzASEhIyP8Pe/ppowoHDTCMn3/O/48TESlIV65cMfbs2WNcuXLFMAzDuHjRMMyIU/DHxYs5rzsuLs4AjBUrVjjPtW3b1hg4cOANX9OjRw/jqaeecj5u166dMXr0aOfjypUrG2+//bZhGIbx888/G97e3sbRo0edzy9atMgAjHnz5t3wM9544w2jSZMmzscvvvii0aBBg+uuS/8+H3/8sVGqVCnjYrob8NNPPxleXl5GfHy8YRiGMWzYMKNy5cpGSkqK85p77rnHGDBgwA1ryfzZFStWNCZNmpThmqZNmxqPPfaYYRiGMWrUKKNjx46G3W6/7r2mTJli3H777UZycvINP88h89+p9HLz+1vdUvmpbVvashqA1astrkVERACoVasWd955J5999hkAv//+O2vWrOGBBx4AIDU1lUmTJlG/fn3KlClDiRIlWLJkCUeOHMnR+8fFxREREUGlSpWc51o6ptCm891339G6dWtCQ0MpUaIE48ePz/FnpP+sBg0aULx4cee5Vq1aYbfb2Zduifw6derg7e3tfBwWFsbJHE7lTUxM5NixY7Rq1SrD+VatWhEXFweYXV+xsbHUrFmTxx9/nCVLljivu+eee7hy5QrVqlXj4YcfZt68eaSkpOTqe+aWwk1+atOGtqwBYPUyjbsREc8WGAgXL1pz5HYs74MPPkh0dDSJiYl8/vnnVK5cmaioKACmTJnC22+/zbPPPsuKFSuIjY2la9euJCfnbN0yI4tNBW2Z+sw2btzIfffdR/fu3VmwYAHbt29n3LhxOf6M9J+V+b2z+sxixYpd95zdnrtFZjN/TvrPbty4MYcOHWLixIlcuXKFe++9l/79+wMQHh7Ovn37+Pe//01AQACPPfYYbdu2zdWYn9zSmJv8VLIkbe84BXGwaasPV6+Cv7/VRYmI5A+bDdI1ILi1e++9l9GjR/PNN9/wxRdf8PDDDzt/Ua9Zs4bevXszePBgwBxDc+DAAe64444cvXft2rU5cuQIx44do2LFioA5zTy9devWUblyZcaNG+c8l3kGl6+vL6mpqTf9rC+++IJLly45W2/WrVuHl5cXt99+e47qvZng4GAqVqzI2rVradu2rfP8+vXradasWYbrBgwYwIABA+jfvz/dunXj7NmzlC5dmoCAAHr16kWvXr0YMWIEtWrVYufOnbc0My0nLG25mTZtGvXr1yc4OJjg4GBatmzJokWLbnh9TEyMc9R4+mPv3r0FWHXuVO9clVCOk5zizebNVlcjIiIAJUqUYMCAATz//PMcO3aM+++/3/lc9erVWbp0KevXrycuLo5//OMfxMfH5/i9O3XqRM2aNRk6dCg7duxgzZo1GUKM4zOOHDnCzJkz+f3333n33XeZN29ehmuqVKnCoUOHiI2N5fTp0yQlXd8DMGjQIPz9/Rk2bBi7du1i5cqVjBo1iiFDhlChQoXc3ZRsPPPMM7z++uvMmjWLffv28dxzzxEbG8vo0aMBnAOG9+7dy/79+5kzZw6hoaGULFmS6dOn8+mnn7Jr1y4OHjzIV199RUBAAJUrV3ZZfZlZGm4qVarEa6+9xpYtW9iyZQsdO3akd+/e7N69O9vX7du3j+PHjzuPGjVqFFDFuWdrlzbuZtUqi4sRERGnBx98kHPnztGpUyciIiKc58ePH0/jxo3p2rUr7du3JzQ0lD59+uT4fb28vJg3bx5JSUk0a9aMhx56iEmTJmW4pnfv3vzf//0fI0eOpGHDhqxfv57x48dnuKZfv35069aNDh06UK5cuSynowcGBvLzzz9z9uxZmjZtSv/+/YmKiuL999/P3c24iccff5ynnnqKp556inr16rF48WLmz5/v/P1bokQJXn/9dSIjI2natCmHDx9m4cKFeHl5UbJkST755BNatWpF/fr1Wb58OT/++CNlypRxaY3p2YysOgctVLp0ad58800efPDB656LiYmhQ4cOnDt3jpIlS97S+ycmJhISEkJCQgLBwcF5rDYHTp/mg3IvMIIP6NQ2maWrfPP/M0VECsDVq1c5dOgQVatWxV997uIC2f2dys3vb7cZUJyamsrMmTO5dOlSlqPK02vUqBFhYWFERUWxcuXKbK9NSkoiMTExw1Ggypal7V+OAbB+kxf5OH5KREREcINws3PnTkqUKIGfnx/Dhw9n3rx51K5dO8trw8LC+Pjjj4mOjmbu3LnUrFmTqKgoVmczz3ry5MmEhIQ4j/Dw8Pz6KjdUu0slSnOGy0k+3MKWJSIiIpILlndLJScnc+TIEc6fP090dDT/+c9/WLVq1Q0DTmY9e/bEZrMxf/78LJ9PSkrKMAgrMTGR8PDwguuWApg9mz4DfPmBPrzxBjzzTMF8rIhIflK3lLiax3RL+fr6Ur16dSIjI5k8eTINGjTgnXfeyfHrW7RowYEDB274vJ+fn3M2luMocOkX81ueuzUMREREJHcsDzeZGYaR5XS3G9m+fTthYWH5WJELhIbSNsJcv2DNWhs3WbZARKRQcbN5KVKIuervkqWL+D3//PN0796d8PBwLly4wMyZM4mJiXHuNDp27Fj+/PNPvvzySwCmTp1KlSpVqFOnDsnJycyYMYPo6Giio6Ot/Bo50rBzOYI+TSThUjA7d0LDhlZXJCKSN47l/JOTkwkICLC4GvEEjhWa028VcSssDTcnTpxgyJAhHD9+nJCQEOrXr8/ixYvp3LkzAMePH8+wz0ZycjJPP/00f/75JwEBAdSpU4effvqJHj16WPUVcsynQxtafbqOxXRn9WqFGxEp/Hx8fAgMDOTUqVMUK1YMLy+36wyQQsRut3Pq1CkCAwPx8clbPLF8QHFBK/B1bhyOHmVyxAc8z2T69b7Gd98Xu/lrRETcXHJyMocOHcr1PkUiWfHy8qJq1ar4+l6/Jlxufn9rb6mCEh5O27Df4DisjrFjGOY+LCIihZmvry81atTI9YaPIlnx9fV1SQugwk0BiuxUEv+vrnAqIYB9+6BWLasrEhHJOy8vL00FF7eiDtIC5NexFS3YCGifKRERkfyicFOQ2rWjHWaqWbksxeJiREREPJPCTUGqUoUO5cwdz2OWp1K0hnKLiIgUDIWbgmSz0aJTCfy5wolzfsTFWV2QiIiI51G4KWB+ndrQinUArFhhcTEiIiIeSOGmoHXsSEfMVLNyqcbdiIiIuJrCTUGrUoUOYfsAiFlpR+teiYiIuJbCjQUiu5ahOBc5e8GXX3+1uhoRERHPonBjgWKd2tGW1QCsXGlxMSIiIh5G4cYKHTrQATPVrFyiJctFRERcSeHGChUr0qHyIQBWrbaRonHFIiIiLqNwY5FG3UMJ4TyJl4uxfbvV1YiIiHgOhRuLeHfqkLYVg8bdiIiIuIzCjVXat3eOu1mxOMniYkRERDyHwo1VypShY81jAKxd78W1axbXIyIi4iEUbixUt3s4ZTjNpaRi/PKL1dWIiIh4BoUbC3lFdaA9MYD2mRIREXEVhRsrtW1LR1sMACsXXbW2FhEREQ+hcGOl4GA61DsNwPpffLiqfCMiIpJnCjcWq9WjGqEc5+o1HzZutLoaERGRwk/hxmK2qI7OKeHLlxkWVyMiIlL4KdxY7c476eQdA8Cyn9QvJSIiklcKN1YLDKRzk7MAbN7hx/nz1pYjIiJS2CncuIHwuxtQk73YDS9txSAiIpJHCjfuoHNnOrEMgGVL7RYXIyIiUrgp3LiDyEg6B64HYOkC7TMlIiKSFwo37sDHh/YdvfAmhQNHA/jjD6sLEhERKbwUbtxEyF2tac4mAJYutbgYERGRQkzhxl2kH3ezSFuEi4iI3CqFG3fxl7/QOWw3AMuX2bFrXLGIiMgtUbhxI83vKksQiZxO9CM21upqRERECieFGzdSrFsU7YkBNO5GRETkVincuJOOHelsM8fdLF2grRhERERuhcKNOylVik51TwCwdqMPV65YXI+IiEghpHDjZmr1up3b+C9JKT6sXWt1NSIiIoWPwo2bsXXpTGfMATdLlxgWVyMiIlL4KNy4mxYt6Oy3GoClP6pfSkREJLcUbtyNry9RbcxF/GL3BXLihMX1iIiIFDIKN26oQs9mNGYrAD//bHExIiIihYzCjTvq3JnuLAJg8YIUi4sREREpXBRu3FGtWnQrvx2AnxfbSU21uB4REZFCROHGHdlstOhdgRDOc/aCL1u2WF2QiIhI4aFw46Z87urqnBK+aKGmhIuIiOSUwo276tiR7t5LAFj8g7ZiEBERySmFG3cVFETXFokAbP7Vn9OnLa5HRESkkFC4cWO39WlKPX7FMGzaJVxERCSHFG7cWffuzinhi37UlHAREZGcULhxZ7Vr063cNgB+XpSK3W5xPSIiIoWAwo07s9lo1asMJbjAyfN+xMZaXZCIiIj7U7hxc753dyGK5QAsWmRxMSIiIoWAwo27i4qiu9f/poTP0y7hIiIiN6Nw4+6CgujW/BwAG7b7cfasxfWIiIi4OYWbQqDyXxtTh12k2r1YvNjqakRERNybwk1h0L07PfkRgAU/aEq4iIhIdiwNN9OmTaN+/foEBwcTHBxMy5YtWXSTUbOrVq2iSZMm+Pv7U61aNT788MMCqtZCderQs9wmwNxn6to1i+sRERFxY5aGm0qVKvHaa6+xZcsWtmzZQseOHenduze7d+/O8vpDhw7Ro0cP2rRpw/bt23n++ed5/PHHiY6OLuDKC5jNRvPeoZTlFOcvFmPdOqsLEhERcV82wzDcasvp0qVL8+abb/Lggw9e99yYMWOYP38+cXFxznPDhw9nx44dbNiwIcv3S0pKIikpyfk4MTGR8PBwEhISCA4Odv0XyC8LFjCs5xm+ZBhP/p/BlLdsVlckIiJSYBITEwkJCcnR72+3GXOTmprKzJkzuXTpEi1btszymg0bNtClS5cM57p27cqWLVu4doO+msmTJxMSEuI8wsPDXV57gYiKoqfvzwAsmJt0k4tFRESKLsvDzc6dOylRogR+fn4MHz6cefPmUbt27SyvjY+Pp0KFChnOVahQgZSUFE7fYNvssWPHkpCQ4DyOHj3q8u9QIAIC6BJlpxjJ7P/Dn/37rS5IRETEPVkebmrWrElsbCwbN27k0UcfZdiwYezZs+eG19tsGbtjHL1qmc87+Pn5OQcsO47CKrhfZ9qxCoAff7S4GBERETdlebjx9fWlevXqREZGMnnyZBo0aMA777yT5bWhoaHEx8dnOHfy5El8fHwoU6ZMQZRrrbvuSpsSHq2uKRERkaxYHm4yMwwjwwDg9Fq2bMnSpUsznFuyZAmRkZEUK1asIMqzVmgoPRuY3WprNhXj3DmL6xEREXFDloab559/njVr1nD48GF27tzJuHHjiImJYdCgQYA5Xmbo0KHO64cPH84ff/zBk08+SVxcHJ999hmffvopTz/9tFVfocBVvSdSqxWLiIhkw9Jwc+LECYYMGULNmjWJiopi06ZNLF68mM6dOwNw/Phxjhw54ry+atWqLFy4kJiYGBo2bMjEiRN599136devn1VfoeD16sXdLABgwfdarVhERCQzt1vnJr/lZp68WzIM1oX1p/WJaEqVSObkOV98fKwuSkREJH8VynVuJIdsNlr0r0Q5TnLuoi+rV1tdkIiIiHtRuCmEvHvfTS/mAzA3ukg1vImIiNyUwk1h1K4dfQPM0cTfz7mG3W5xPSIiIm5E4aYw8vUlqrsvQSTy5ylffvnF6oJERETch8JNIeXX727u4icA5s61uBgRERE3onBTWN19N319/jfuZmYyRWvOm4iIyI0p3BRWwcF075iMH1f57Ygvu3dbXZCIiIh7ULgpxErc24MuLAFg3jyLixEREXETCjeFWa9e/NX2AwBzZ2ojTREREVC4KdzKlaNny9N4k0LsHj8OHbK6IBEREesp3BRyZe/rRDtWAeqaEhERAYWbwu+vf6Uv5lzw775JtrgYERER6yncFHaVKtG30WFs2Nmw1Zd0m6iLiIgUSQo3HiDsvna0xdxBc/Zsi4sRERGxmMKNJ/jrXxnALABmfZ1icTEiIiLWUrjxBDVq0K/2XrxIZUusD7//bnVBIiIi1lG48RDlB3ehIysAdU2JiEjRpnDjKQYMSNc1dc3iYkRERKyjcOMpqlWjb6PD+HCNHbuLsW+f1QWJiIhYQ+HGg5Qe3IPOLAXUNSUiIkWXwo0nuffetK6pGeqaEhGRoknhxpNUqkTvFifxJYnd+4uxa5fVBYmIiBQ8hRsPU3Lw3XRnEQBff21xMSIiIhZQuPE0/fsz2PYNAF9/kYLdbnE9IiIiBUzhxtNUqMDd7S4QwnmOHvdh1SqrCxIRESlYCjceyH9QP+7FnC711VcWFyMiIlLAFG48Ub9+DPGZCcB3s1O5fNniekRERAqQwo0nKlWKVr3KUIVDXLjkzfz5VhckIiJScBRuPJTXsCEMZgYAX32pUcUiIlJ0KNx4qm7dGFJyAQA//wwnTlhcj4iISAFRuPFUvr7cPrgZzdhEqt2LmTOtLkhERKRgKNx4siFDGII5XerL6akWFyMiIlIwFG48WdOm3PeXLRQjmW2x3uzYYXVBIiIi+U/hxpPZbJT9e0/68D0An35qbTkiIiIFQeHG0w0ezEP8B4CvvrBz5YrF9YiIiOQzhRtPV7kyndpeI4I/OJ/oxbx5VhckIiKSvxRuigCvhx7gAT4D4D//MSyuRkREJH8p3BQF/frx96BobNhZudLG779bXZCIiEj+UbgpCgIDiRjSjq78DMBnn1lcj4iISD5SuCkqHnrIObD4809TSUmxuB4REZF8onBTVDRqRM+G/6UcJzl+wptFi6wuSEREJH8o3BQhvv/4O0P5EoAPP9TAYhER8UwKN0XJwIEM95sOwKJFaGCxiIh4JIWboiQkhOr3RdKNRRiGjWnTrC5IRETE9RRuipqHHmIE/wbgs0/tXL5scT0iIiIupnBT1LRqRffaR6jCIc6d92LmTKsLEhERcS2Fm6LGZsN75KM8xgcA/PvfBobGFouIiAdRuCmKBg/mgRJz8OcK27bZ2LTJ6oJERERcR+GmKAoKosz9PbkPs0/q3/+2uB4REREXUrgpqkaMcA4snj3b4MQJi+sRERFxEYWboqpWLSKjStKCDSQn29R6IyIiHkPhpigbMYKnmALABx8YmhYuIiIeQeGmKOvZk79W2kJVDnLmjI0vv7S6IBERkbxTuCnKfHzwfvQRnmAqAG+/bWC3W1uSiIhIXincFHX/+AcP+H9LSc6xf7+NBQusLkhERCRvXBpufv/9dzp27Jjj6ydPnkzTpk0JCgqifPny9OnTh3379mX7mpiYGGw223XH3r1781p+0VSmDCUeuJd/8BEAU6ZYXI+IiEgeuTTcXLx4kVWrVuX4+lWrVjFixAg2btzI0qVLSUlJoUuXLly6dOmmr923bx/Hjx93HjVq1MhL6UXb//0fo3gfH66xejVs2WJ1QSIiIrfOx8oPX7x4cYbHn3/+OeXLl2fr1q20bds229eWL1+ekiVL5mN1RUj16tzWpykDv/+WrxjKv/6F9pwSEZFCy63G3CQkJABQunTpm17bqFEjwsLCiIqKYuXKlTe8LikpicTExAyHZOGpp3iafwEwZ47BgQMW1yMiInKL3CbcGIbBk08+SevWralbt+4NrwsLC+Pjjz8mOjqauXPnUrNmTaKioli9enWW10+ePJmQkBDnER4enl9foXBr1Yr6zQK4mx+x22289prVBYmIiNwam2HkfE/oRo0aYbPZbvj85cuXOXDgAKmpqbkuZMSIEfz000+sXbuWSpUq5eq1PXv2xGazMX/+/OueS0pKIikpyfk4MTGR8PBwEhISCA4OznWdHm32bDYOeIuWbMTHx+C332xUrmx1USIiIubv75CQkBz9/s7VmJs+ffrkpa4bGjVqFPPnz2f16tW5DjYALVq0YMaMGVk+5+fnh5+fX15LLBr69qVFlTF0PLycFSlRvPkmvP++1UWJiIjkTq5ablzNMAxGjRrFvHnziImJueUZT/379+fs2bOsWLHiptfmJvkVSR98wIoR3xHFCvz8DA4fthEaanVRIiJS1OXm97dLx9zs2LEDb2/vHF8/YsQIZsyYwTfffENQUBDx8fHEx8dz5coV5zVjx45l6NChzsdTp07l+++/58CBA+zevZuxY8cSHR3NyJEjXflViq4HHqBDhThasIGkJBtvvWV1QSIiIrnj8gHFuWkImjZtGgkJCbRv356wsDDnMWvWLOc1x48f58iRI87HycnJPP3009SvX582bdqwdu1afvrpJ/r27evS71Fk+ftje/opxjEJgGnTDM6etbgmERGRXHBpt9SOHTto3LjxLQ0oLijqlsqBixcxIirT6NxydtCQcePglVesLkpERIoyy7qlxEOUKIHtidFMYAIAU6canDplbUkiIiI5latwk3kxvMzHhQsX8qtOKWijRtG7+HKasIVLl2y8/rrVBYmIiORMrrqlvLy8sl3nxjAMbDabuqU8xZgxLHrjV3qwCH9/g4MHbYSFWV2UiIgURfm2zs2KFSuyDTfiYZ58km7vVePOK+tYf7UVr74K771ndVEiIiLZs3SdGyuo5SaXnnuOla9voiMr8fU1OHDARkSE1UWJiEhRk28Dir28vPD29s728PGxdKNxcbVnnqFD0FY6sILkZJtmTYmIiNvLVcvNDz/8cMPn1q9fz3vvvYdhGBkW4XM3arm5BS+8wLqJy2nNOry9DfbutVG9utVFiYhIUZKb39957pbau3cvY8eO5ccff2TQoEFMnDiRCDfut1C4uQXnz0PVqvQ4/zWL6MGAATBzptVFiYhIUVIg69wcO3aMhx9+mPr165OSkkJsbCxffPGFWwcbuUUlS8JTTzGZsdiwM2sWbN5sdVEiIiJZy3W4SUhIYMyYMVSvXp3du3ezfPlyfvzxR+rWrZsf9Ym7GD2aBmX+ZChfAvDMM1C0hqKLiEhhkatw88Ybb1CtWjUWLFjAt99+y/r162nTpk1+1SbuJCgIxozhFf6Jv+0qq1fDjz9aXZSIiMj1cr2IX0BAAJ06dcp29++5c+e6pLj8oDE3eXD5MtSowfPHRjCZ56lVC3buBE2QExGR/JZvi/gNHTpUi/gVZYGB8PLLjHnoST6xPcLevWX5z39g+HCrCxMREUmjRfwkd1JSoGFD3tvdgcd5j/Ll4bffzF4rERGR/KJdwSX/+PjA66/zDz6iuu03Tp6E116zuigREZE0CjeSez164Nu+FW8aTwMwZQocPGhxTSIiIv+jcCO5Z7PBG2/Qmx/ozBKSkuCpp6wuSkRExKRwI7emaVNs993HVJ7A25bK99/DkiVWFyUiIqJwI3kxaRK1fX9nlPEuAKNHw7VrFtckIiJFnsKN3Lpq1eDJJ3mRlyjndYa9e+H9960uSkREijqFG8mb55+nZFggk+3PAjBhApw8aW1JIiJStCncSN4EBcFrr/F3PifSayuJiea+UyIiIlZRuJG8GzwYr+bN+Lf9UWzY+fJLWLnS6qJERKSoUriRvPPygnffpRm/8CjTAHNLhqQki+sSEZEiSeFGXKNZM7j/fl7leUKLnWb/fq1cLCIi1lC4EdeZPJmQIIN3rj0GwKuvwv79FtckIiJFjsKNuE5oKEyaxD3MoZvPUpKTze6porU1q4iIWE3hRlzrscewNWnCv1P+gb93MitXwldfWV2UiIgUJQo34lre3vDRR1Tz+oMXU18AzH2nTp2yuC4RESkyFG7E9Zo0gREjeIop1PPdy+nTMHKk1UWJiEhRoXAj+WPiRIqFlePz5EF42+zMng3ffWd1USIiUhQo3Ej+CAmBqVNpwjaes70OwGOPwenTFtclIiIeT+FG8s8990C3boy3T6BO4EFOnYJRo6wuSkREPJ3CjeQfmw2mTcOveDGmX74Xby87M2fC3LlWFyYiIp5M4UbyV5Uq8PrrRLKVZ72nAPDoo3DmjLVliYiI51K4kfz36KPQti0vXvsntYsf5uRJ85QW9xMRkfygcCP5z8sLPv0UvwBvvrjUHx8vO3PmwJdfWl2YiIh4IoUbKRjVq8MrrxDJVl7ymQiYa9/8/rvFdYmIiMdRuJGCM3o0tGjBmOSXaVNqFxcvwuDBkJJidWEiIuJJFG6k4Hh7w2ef4e1XjK/O3UWwfxIbN8Irr1hdmIiIeBKFGylYd9wBkydTmSNMsw8HYOJE2LDB4rpERMRjKNxIwRs9GqKi+FvydAaVXoTdDoMGQUKC1YWJiIgnULiRguflBdOnQ8mS/PvsfVQpeY5Dh+CBBzQ9XERE8k7hRqxRqRJ89BEhJDIroTvFfOzMnQvvvmt1YSIiUtgp3Ih17r0XBg+mmbGJKSHm9PCnn4aNGy2uS0RECjWFG7HW++9DRAQjz0ygf8RmUlJgwABtzyAiIrdO4UasFRICM2Zg8/bmP0c6U718IkeOwNChYLdbXZyIiBRGCjdivTZtYOJEQkhkTkIX/HztLFwIkydbXZiIiBRGCjfiHsaMga5daZi0ifdLvwjA+PHw008W1yUiIoWOwo24By8vcyfNihV5KP4Vht++AsOAv/0N9u61ujgRESlMFG7EfZQvD99+C15evLO/G61rnCAxEXr3hvPnrS5OREQKC4UbcS9t28LEifhyje+ONic8NJn9+80VjFNTrS5OREQKA4UbcT/PPQfdu1Ph6h98z1/x9zdYuBDGjrW6MBERKQwUbsT9eHnBN99A9eo0jl/IZ9UmAfDmm/DRRxbXJiIibk/hRtxTyZLw/fdQogQD94zn5ZYLARgxAhYtsrQyERFxc5aGm8mTJ9O0aVOCgoIoX748ffr0Yd++fTd93apVq2jSpAn+/v5Uq1aNDz/8sACqlQJXp445gwr454a7uL/Nb6Smmrs2xMZaW5qIiLgvS8PNqlWrGDFiBBs3bmTp0qWkpKTQpUsXLl26dMPXHDp0iB49etCmTRu2b9/O888/z+OPP050dHQBVi4F5q9/hfHjsQEfbWpEVNNELl6Eu+6C//7X6uJERMQd2QzDMKwuwuHUqVOUL1+eVatW0bZt2yyvGTNmDPPnzycuLs55bvjw4ezYsYMNGzbc9DMSExMJCQkhISGB4OBgl9Uu+chuN+eDL1jA+fK307rkTnbv96V2bVi9GsqUsbpAERHJb7n5/e1WY24SEhIAKF269A2v2bBhA126dMlwrmvXrmzZsoVr165dd31SUhKJiYkZDilkvLzg66+hXj1KntzPQtvd3FbRzp490KMHXLhgdYEiIuJO3CbcGIbBk08+SevWralbt+4Nr4uPj6dChQoZzlWoUIGUlBROnz593fWTJ08mJCTEeYSHh7u8dikAwcGwYAGEhhKxbylLqvyDMmUMNm+GPn3g6lWrCxQREXfhNuFm5MiR/Prrr3z77bc3vdZms2V47OhZy3weYOzYsSQkJDiPo0ePuqZgKXgREWbACQyk9vr/sKjta5QoYbBiBQwcCCkpVhcoIiLuwC3CzahRo5g/fz4rV66kUqVK2V4bGhpKfHx8hnMnT57Ex8eHMlkMvvDz8yM4ODjDIYVYkybmFg02G03nPc/8+77Fz8+cNf7AA1rFWERELA43hmEwcuRI5s6dy4oVK6hatepNX9OyZUuWLl2a4dySJUuIjIykWLFi+VWquJNeveDttwHo8J9BzHpoCd7e8NVXCjgiImJxuBkxYgQzZszgm2++ISgoiPj4eOLj47ly5YrzmrFjxzJ06FDn4+HDh/PHH3/w5JNPEhcXx2effcann37K008/bcVXEKuMHm1u0wD0ntadmf+3EW9vc1mcv/9dAUdEpCizNNxMmzaNhIQE2rdvT1hYmPOYNWuW85rjx49z5MgR5+OqVauycOFCYmJiaNiwIRMnTuTdd9+lX79+VnwFsdKrr8JDD4HdTv932zFz3E5nC44CjohI0eVW69wUBK1z42EcSxbPnQslSvDduO3c98/qpKbC3/4G06eDeitFRAq/QrvOjUiueXubm2x27AgXL9L/jWbMnHwIHx/zdN++kK6XU0REigCFGyn8HNOlWraEc+fo/1ok8946iL+/OXO8a1f43/qQIiJSBCjciGcICoLFi6FFCzh7lrtfasbPH/xOcDCsWQPt28OJE1YXKSIiBUHhRjxHcLAZcJo1gzNnaPtsC2I+OUD58uYu4q1aQQ42nRcRkUJO4UY8S0gI/PwzREbC6dM0erQFaz/4lSpV4PffzZ6r1autLlJERPKTwo14npIlYckSaN4czp6lxt9bs/Gt9TRvDufOQadO5nRxERHxTAo34plKlYKlS6FDB7hwgQp/i2Lls4vo3x+uXYOhQ+GFF8But7pQERFxNYUb8VxBQbBwIfTsCVevEjCgF7P6fOtY2JiJE6F3bzh/3tIqRUTExRRuxLP5+0N0tLmiX0oKXoP/xuSSr/PFdMM5VbxZM9i1y+pCRUTEVRRuxPMVK2YOshk92nz83HMM3fAo61alULkyHDhgziCfPdvaMkVExDUUbqRo8PKCqVPNw2aDjz6i8YRebIm5SKdOcOkSDBgAjz8OV69aXayIiOSFwo0ULaNHm/tQBQTAokWU7duWRR8fZcwY8+n33jMnWcXFWVumiIjcOoUbKXr69IGVK6FcOdi+HZ8WkbzWYzULF5qnfv0VmjSBTz6BorWtrIiIZ1C4kaKpeXPYvBkaNICTJyEqiu6/v8+vOww6dzY323zkEejf33xaREQKD4UbKbqqVIH16+G++yAlBUaNInTcgyz+/ipvvAE+PmYPVp06MGeO1cWKiEhOKdxI0RYYCN98A2++aQ46/vxzvNq04pm//sbmzVCvHpw+Dffeax6nTlldsIiI3IzCjYjNBk8/be5JVaYMbNsGjRvTaO+3bNkC48eDt7fZelOnDnz9tcbiiIi4M4UbEYdOncztw9u0gQsX4G9/w/exh3j5ucvOVpxTp2DwYIiKgr17rS5YRESyonAjkl6lSrBihdlcY7PBp59C06Y0tm1nyxaYNMlc9HjlSqhfH8aNg8uXrS5aRETSU7gRyczHB15+GZYtg9BQ2LMHmjXD941XeP7ZFPbsgbvuMjfgfPVVs6sqOlpdVSIi7kLhRuRGOnY0F73p29ecTTV+PNx5J1WT9vLjjzBvHoSHw+HD5pTxtm3hl1+sLlpERBRuRLJTrhx89x3MmAElS5rppVEjbFP+RZ+7zVacF14wFzxeu9bchHPwYDhyxOrCRUSKLoUbkZux2WDQIHPr8K5dzc2nnnkGmjWjxN4tvPQS7N8PQ4eal3/9NdSsCU89pQUARUSsoHAjklO33QaLFsF//gOlSsH27eZKx6NHUynkAl98AVu2QLt2Zv556y2oVg3GjoWzZ60uXkSk6FC4EckNmw0efNCcBz5oENjt8O67cMcdEB1Nk8YGK1eaGSgy0txt/LXXoGpVmDABEhKs/gIiIp5P4UbkVpQvb47DWbIE/vIX+PNPc1Rxx47Yft1Bt27m1lU//GBOGU9MhJdegogIsyUnPt7qLyAi4rkUbkTyonNn2LnTnEnl7w8xMdC4MQwfju30KXr1MnuvZs+G2rXNkPPaa+a2VsOHw2+/Wf0FREQ8j8KNSF4FBJjr4uzda25AZbfDRx9BjRrwr3/hlXSFe+4xM9APP0DLlpCUZF5SsyYMGKAp5CIirqRwI+IqlSvDrFmwahU0amQOsHnmGTPkfPIJXvYUevWCdetg9Wro0cPMQbNnm1PIW7QwZ1olJ1v9RURECjeFGxFXc6zm99ln5ip/f/4JjzxiLmU8ezY2w06bNvDTT+ZWVkOGgK8vbNpkrpETEQEvvgjHjln9RURECieFG5H84O0Nf/+7uQDO229D2bLmnwcMMKdRzZsHdjsNGsCXX5qL/k2cCBUrwokTZi9X5crm5UuXmi08IiKSMzbDKFo74iQmJhISEkJCQgLBwcFWlyNFxYUL5sI3U6aYfwazJWfcOHOcjrc3YO5XNW8evPeeueKxQ0SEmZX+/ncz9IiIFDW5+f2tcCNSkE6fhqlTzfSSmGieq1HDnB8+eDAUK+a8NDbWXC/w66/h/HnznM0GnTqZS+306QN+fgVcv4iIRRRusqFwI27h/Hl4/32zy8qxfHFEBIwaBQ89ZO5j9T9XrpitOZ9+CitWpL1FSAj062euJdiunbPxR0TEIyncZEPhRtzKxYvw4Yfwr3+Zg20ASpSABx6A0aPN/RvSOXgQPv8cpk+H//437XxYGNx3H/ztb9CkidnCIyLiSRRusqFwI27p6lWz/+mtt2DPHvOczWb2PY0ebc7ASpdY7HZzTM4338CcORn3rqpRwww6fftCgwYKOiLiGRRusqFwI27NMMzpUW+9BT//nHb+jjvMJY2HDs3QZQXmujg//2wGnR9+MLuxHKpWNUNO377mOjpemh8pIoWUwk02FG6k0NizB955x9zD6vJl81xAAAwcaAadyMjrmmUuXjQDTnQ0LF6cMeiEhZkNQX37mmN00o1dFhFxewo32VC4kUInIcHsspo2DXbtSjvfqBHcf7850KZs2etedumS2aIzdy78+GPa5CyA4GDo0gXuugu6d4cKFfL/a4iI5IXCTTYUbqTQMgzYsMEcgDx7trlBFZhNMHfdBcOGmXs6+Ppe99LkZHOm1dy58P33cOpUxucjI823uOsuc0Cyuq9ExN0o3GRD4UY8wpkz5iCbL76ArVvTzpcta7bkDBlyw2lTdru5O8TCheYWEOlfDlC+PHTrZrbsREVBaGg+fxcRkRxQuMmGwo14nF27zJAzYwbEx6ed/8tfzNWPBwyA+vVvOG3q+HFYtMgMO0uWpC2g7FC3rrlwYKdO5qStoKB8/C4iIjegcJMNhRvxWCkp5kyrL76A+fMzjiauVSst6NSufcO3SE42p5gvWQLLlsG2bWZvmIOPjznryhF2mjXTwGQRKRgKN9lQuJEi4dIlWLAAZs0ym2Qc43PAbIrp18+cOnWThXDOnIGVK82gs2wZ/P57xucDA6FlS7NFp21baN7cnNAlIuJqCjfZULiRIicx0WzJmTXLnD517Vrac5UrQ69e0Lu3mU5u0gxz6BAsX24GneXLza2y0vP1NVtzHGHnzjvVjSUirqFwkw2FGynSzp0zF8L54Qcz6KTvuipZ0pwu1bs3dO1qzhfPht0OcXGwerV5rFpljt9Jz8sLGjeGNm3MFp4WLSA83PVfS0Q8n8JNNhRuRP7n8mWzCeaHH8yWnfTNMD4+0KqVuQhOt27ZDkh2MAxz76tVq9ICz6FD1193221m0HEcjRtrd3MRuTmFm2wo3IhkITXVXEPH0apz4EDG58PCzJDTrRt07gylSuXobY8eNUPO+vXm2//6q/lR6fn6mgGnRYu0wKPWHRHJTOEmGwo3Ijnw229mt9WiRebqf+m7r7y8zCTSpQt07GiOIs5i4cCsXLpkrrGzYUPakXncDphZKjISmjY1f0ZGQrlyLvpuIlIoKdxkQ+FGJJeuXoU1a8zNqhYvTtu13CEwEFq3Nlf869jR3BbC2ztHb+3oykofdrJq3QGIiMgYdpo0yXEDkoh4AIWbbCjciOTRH3+YrTorVphH5r0cQkKgfXsz6HToAHXq5Go/h0uXIDYWtmwxj19+gX37sr62evWMYadBAwUeEU+lcJMNhRsRFzIM2L3bnBe+YgXExGTcoRPMtNGqldm606aNmUJyOYI4MdFcUDB94Dl4MOtrK1eGhg3NBqSGDc0jIuKm46FFxM0p3GRD4UYkH6WkwPbtaa06a9eas7LS8/c3F8Np3do87rzTbO3JpbNnzX2xHGEnNjbr2Vlg5itH0HEEn1q1tLqySGGicJMNhRuRAnTtmpk61q41x+2sXXt9N5bNZk41b9XKHKjcvDnUqHFLTS3nz8OOHeZHxsaaOWv3bjNzZebray7W3LCh2Z1Vty7Uq6eByyLuSuEmGwo3IhYyDHOauSPorF1rzszKrHRps3WneXMz8DRrZp67BUlJ5mKD6QNPbOz1vWcOFSqYISf9Ubu2OW5aRKyjcJMNhRsRN3P8uBlyNm40j23bzBlamd1+uxl2HIGnXr0cT0HPzDDg8OG0sLNzp3kcPJhxo1AHm83cZD1z6PnLX8z1DkUk/xWacLN69WrefPNNtm7dyvHjx5k3bx59+vS54fUxMTF06NDhuvNxcXHUqlUrR5+pcCPi5pKTzfngmzaZx8aN1y8qCGawqV/fHKDcuLH5s27dPC13fOmS2Y3lCDuOI3NPmoOfn9mq4wg7deqYj8PDczVBTERyIDe/vy39f45Lly7RoEED/v73v9OvX78cv27fvn0Zvlg5dZKLeA5f37T53SNGmOfOnoXNm82g4wg9586lTZ9yKFbMTBmOsNOkifnY3z9HH128uNkD1qxZxvMnT14feHbvNsdKb99uHpnf54470sKO46hSRaFHpCC4TbeUzWbLccvNuXPnKFmyZI7eNykpiaSkJOfjxMREwsPD1XIjUpgZhjk1auvWjMe5c9df6+Njtug0bmweDRqYLT55/Pffbje7sRxhZ9cuc33D/fszbryeXkCAGXrSB57ataFatRyveyhSZBWabqn0chNuqlSpwtWrV6lduzb//Oc/s+yqcpgwYQIvvfTSdecVbkQ8jGGYCwxmDjxnzmR9fZUqZtBJf1StmuemlWvX4PffzaCzZ4/ZwrNnD+zda/a4ZcXPz5yanjn0VK+uMT0iDh4bbvbt28fq1atp0qQJSUlJfPXVV3z44YfExMTQtm3bLF+jlhuRIswwzN07HUEnNtacK/7f/2Z9fYkSZqtO+sBTr57Zz5RHKSlmY1Pm0BMXl/X4aTB72WrWNIOOo8XnjjvMsdXaSV2KGo8NN1np2bMnNpuN+fPn5+h6DSgWEc6cMQct79iRduzenXXTis1mNqE4RgzXrWv+vP12l6wCmJpqNjilDzyO0HPpUtav8fIyZ2plDj21apn5TMQTFalwM2nSJGbMmEFcXFyOrle4EZEsXbtmbmKVPvDs2AEnTmR9fbFiZsCpWzct8NSt67IBNHa72ei0e7cZdByBZ88eSEi48esiIq4PPbVra88tKfyKVLjp378/Z8+eZcWKFTm6XuFGRHLlxIm0lp1du8yfu3fDxYtZX+/vnzZVyhF66tQxN71ywVQpw4D4+Ixhx/Hz5Mkbv65ChaxDT4UK2ndLCodCMxX84sWL/JZuddJDhw4RGxtL6dKliYiIYOzYsfz55598+eWXAEydOpUqVapQp04dkpOTmTFjBtHR0URHR1v1FUTE01WoAF26mIeDo1nFEXYcP/fsMQfQ3Gh+uCNVOI5atXK9EqDNBmFh5hEVlfG5M2fMoJM59Bw9ama0Eydg5cqMrylZMuvQo7V6pDCztOXmRovyDRs2jOnTp3P//fdz+PBhYmJiAHjjjTf4+OOP+fPPPwkICKBOnTqMHTuWHj165Pgz1XIjIvkmNdUcNZw59Ozde+P54cWKmXtp1aqVMfTUquWSgcwAFy6YJWQOPQcPmjktK4GB1weeO+4we900g0usUCi7pQqKwo2IFLhr18w9tBwDaBxJY+9euHLlxq+LiMgYehzBp1w5l/QlXb1qrsuTOfRkt1aPr6851EgzuKSgKdxkQ+FGRNyGo3vL0ZfkCD1xcXD69I1fV7p0WtBx/KxZ01y7xwXNKikp5lo9mUPP3r3mqsxZ0QwuyW8KN9lQuBGRQuH0aTNNpA88e/eaO37e6D/bxYqZCaNmTfO4/fa0P5ctm+fWHrsdjhy5PvTcygyuO+645Y3epYhSuMmGwo2IFGqXL5v9RulDz7595rkbrQYI5shhR9BJH3yqVzf3hcgDzeCSgqBwkw2FGxHxSI4urv37zbDjOPbvN5tbbvSfepvNbFrJKvhUqpTnKVPZzeC6Ec3gkqwo3GRD4UZEipwrV+DAgbSwkz78ZNefFBBgzuTKqpsrJCRPJeVlBlfm0KMZXEWDwk02FG5ERP7HMODUqYytPI4///67ObL4RsqXz7q1p1q1PG1LoRlcciMKN9lQuBERyYFr18zBy1kFn/j4G7/Ox8cMODVrpq3X4/hzmTK3XM6tzuBybAuWfi/UiAiN6SmMFG6yoXAjIpJHCQlp3Vzpw8/+/TdOGmCGG0fYcQSePLb23GgGV1wcnD+f9WtKlsy4+XvDhuYOGf7+t1SCFBCFm2wo3IiI5BO7Hf78My3w7N2b9jO7EcQ+PuYU9vStPI6ftzhf3DGDa/fujPug7tmTdW+bt7f5kelbeBo0gNBQtfK4C4WbbCjciIhY4NKltK6t9KHnZq09ZctmHXqqVr2lUcTJyWarTvrAExtrzurKSrly0KgRNGkCkZHmT3VrWUPhJhsKNyIibsRuh//+9/rQs2+fef5GihUzB9SkH9vjGE2cyyWRDQOOHcsYeHbsMHNXVjO3ypQxQ076o3JlBZ78pnCTDYUbEZFC4uLFtAUL04eeffuyX7CwcmUz5NSpYx61a99S6Ll82dz7dNs22LrVPHbuzLpbq0wZaNw4rXVHgcf1FG6yoXAjIlLIORYsTB92HCOJT5y48etcEHqSksyAs2VLWuDZtSvraerlykHz5tCihfmzadM8Lw9UpCncZEPhRkTEg505Y4ac3bvNw/Hn3ISeevVyNX3KEXgcYcfRwpM58Nhs5sekDzx16piDmeXmFG6yoXAjIlIEpQ896cPPjUKPt7e5CmCDBmnzxuvXh9tuy1Ff09Wr5kDlTZtg40bzOHz4+utKlDC7slq0MI9Wrcwx1HI9hZtsKNyIiIiTI/Q4As+uXfDrrzeePlW6dMaw06CB2RyTg81HT5www44j8Pzyi7kNRWa1akHr1mlHtWoauwMKN9lSuBERkWwZBhw/boacHTvSfu7dC6mp11/v5ZW2SI5jNHGjRuZqgdlITTWHCjnCzvr1ZsbKLDTUDDlt2pg/69cvmntpKdxkQ+FGRERuSVKSmT4yh57Tp7O+/i9/yThfvHFjKFUq2484c8YMOWvXmscvv1w/dqdECWjZMi3wtGxZNFZXVrjJhsKNiIi4jGMp5B07YPv2tBHFWQ2wAXPxwcyL5GSzCvOVK2bAcYSddesgMTHjNX5+ZsBp3x46dDAHKnvihqEKN9lQuBERkXx35oy5QE76RXIOHsz62ho10qZQtWhh9jvdYK+t1FRzaNCaNeaxatX1+5j6+8Odd5pBp0MHcwq6r6+Lv58FFG6yoXAjIiKWOHfu+sDz22/XX+fvb7bopJ8zHh6e5ahiwzDXOVy50jxiYuDkyYzXBAaas7AcYadJk1vep9RSCjfZULgRERG3cfYsbN6cNqp40yYzBGUWFpYWdlq3NuePZ9H3ZBjmIGVH0ImJuX5IUIkS0K4ddOpkHnXqFI7ZWAo32VC4ERERt2UYcOBAWtDZuNEcuJx5zwc/P2jWLG2++J13Zjk7y243x0A7WnZWrTLzVHoVKqQFnU6doFKl/Pt6eaFwkw2FGxERKVQuXza7sjZtSptKlbnvyWaDunXT5ou3bm12ZWVit5tZadky81i92hy0nF7NmmlBp337m85oLzAKN9lQuBERkULNMMyxOmvXmqOK1641W3syi4gwQ07btmZKuf326/qfkpJgw4a0sPPLLxl3QvfyMgckO8JOy5bWzcRSuMmGwo2IiHicEyfMeeKOwLN9+/ULDoaFmSHHMWe8evXrws758+Y4HUfY2bcv41sEBJhZyRF26tc3A1BBULjJhsKNiIh4vIsXzW4sx3zxDRvMZpr0brstLey0b28uOpgp7Bw9CsuXw9KlZtjJ3BtWtixERZlBp3Nncw/S/KJwkw2FGxERKXKuXjUHJ8fEmCOLN26E5OSM11SqlLFlp2rVDGHHMMyttxytOqtWwaVLGd+ievW0Vp2ePV27vo7CTTYUbkREpMi7csVszXHMF9+48fp9HsLDzZATFQUdO143jSo52WwcWrrUbN3ZtCmtJywoyJyV5co9sBRusqFwIyIiksnly2bYcSyQs2nT9dPPb7/dDDlRUWbrTtmyGZ5OTDRbc5YtMx+/845rS1S4yYbCjYiIyE1cumQOUF650myW2bo14zQqgIYN08JOmzZmc00+UrjJhsKNiIhILp0/bzbLrFhhhp3duzM+7+NjLiro6MLKhznjCjfZULgRERHJoxMnzKDjODJvClqihDm1KiDAZR+Zm9/fLhzqIyIiIkVChQowcKB5ABw+nNaqs2KFuYCgC4NNbqnlRkRERFzHMMypUmXKuPRtc/P7u4DWFRQREZEiwWZzebDJLYUbERER8SgKNyIiIuJRFG5ERETEoyjciIiIiEdRuBERERGPonAjIiIiHkXhRkRERDyKwo2IiIh4FIUbERER8SgKNyIiIuJRFG5ERETEoyjciIiIiEdRuBERERGP4mN1AQXNMAzA3DpdRERECgfH723H7/HsFLlwc+HCBQDCw8MtrkRERERy68KFC4SEhGR7jc3ISQTyIHa7nWPHjhEUFITNZnPpeycmJhIeHs7Ro0cJDg526XtLGt3ngqH7XHB0rwuG7nPByK/7bBgGFy5coGLFinh5ZT+qpsi13Hh5eVGpUqV8/Yzg4GD9i1MAdJ8Lhu5zwdG9Lhi6zwUjP+7zzVpsHDSgWERERDyKwo2IiIh4FIUbF/Lz8+PFF1/Ez8/P6lI8mu5zwdB9Lji61wVD97lguMN9LnIDikVERMSzqeVGREREPIrCjYiIiHgUhRsRERHxKAo3IiIi4lEUblzkgw8+oGrVqvj7+9OkSRPWrFljdUmFyuTJk2natClBQUGUL1+ePn36sG/fvgzXGIbBhAkTqFixIgEBAbRv357du3dnuCYpKYlRo0ZRtmxZihcvTq9evfjvf/9bkF+lUJk8eTI2m40nnnjCeU732TX+/PNPBg8eTJkyZQgMDKRhw4Zs3brV+bzus2ukpKTwz3/+k6pVqxIQEEC1atV4+eWXsdvtzmt0r3Nv9erV9OzZk4oVK2Kz2fj+++8zPO+qe3ru3DmGDBlCSEgIISEhDBkyhPPnz+f9CxiSZzNnzjSKFStmfPLJJ8aePXuM0aNHG8WLFzf++OMPq0srNLp27Wp8/vnnxq5du4zY2FjjrrvuMiIiIoyLFy86r3nttdeMoKAgIzo62ti5c6cxYMAAIywszEhMTHReM3z4cOO2224zli5damzbts3o0KGD0aBBAyMlJcWKr+XWNm/ebFSpUsWoX7++MXr0aOd53ee8O3v2rFG5cmXj/vvvNzZt2mQcOnTIWLZsmfHbb785r9F9do1XXnnFKFOmjLFgwQLj0KFDxpw5c4wSJUoYU6dOdV6je517CxcuNMaNG2dER0cbgDFv3rwMz7vqnnbr1s2oW7eusX79emP9+vVG3bp1jbvvvjvP9SvcuECzZs2M4cOHZzhXq1Yt47nnnrOoosLv5MmTBmCsWrXKMAzDsNvtRmhoqPHaa685r7l69aoREhJifPjhh4ZhGMb58+eNYsWKGTNnznRe8+effxpeXl7G4sWLC/YLuLkLFy4YNWrUMJYuXWq0a9fOGW50n11jzJgxRuvWrW/4vO6z69x1113GAw88kOFc3759jcGDBxuGoXvtCpnDjavu6Z49ewzA2Lhxo/OaDRs2GICxd+/ePNWsbqk8Sk5OZuvWrXTp0iXD+S5durB+/XqLqir8EhISAChdujQAhw4dIj4+PsN99vPzo127ds77vHXrVq5du5bhmooVK1K3bl39s8hkxIgR3HXXXXTq1CnDed1n15g/fz6RkZHcc889lC9fnkaNGvHJJ584n9d9dp3WrVuzfPly9u/fD8COHTtYu3YtPXr0AHSv84Or7umGDRsICQmhefPmzmtatGhBSEhInu97kds409VOnz5NamoqFSpUyHC+QoUKxMfHW1RV4WYYBk8++SStW7embt26AM57mdV9/uOPP5zX+Pr6UqpUqeuu0T+LNDNnzmTbtm388ssv1z2n++waBw8eZNq0aTz55JM8//zzbN68mccffxw/Pz+GDh2q++xCY8aMISEhgVq1auHt7U1qaiqTJk1i4MCBgP5O5wdX3dP4+HjKly9/3fuXL18+z/dd4cZFbDZbhseGYVx3TnJm5MiR/Prrr6xdu/a6527lPuufRZqjR48yevRolixZgr+//w2v033OG7vdTmRkJK+++ioAjRo1Yvfu3UybNo2hQ4c6r9N9zrtZs2YxY8YMvvnmG+rUqUNsbCxPPPEEFStWZNiwYc7rdK9dzxX3NKvrXXHf1S2VR2XLlsXb2/u6lHny5MnrUq3c3KhRo5g/fz4rV66kUqVKzvOhoaEA2d7n0NBQkpOTOXfu3A2vKeq2bt3KyZMnadKkCT4+Pvj4+LBq1SreffddfHx8nPdJ9zlvwsLCqF27doZzd9xxB0eOHAH099mVnnnmGZ577jnuu+8+6tWrx5AhQ/i///s/Jk+eDOhe5wdX3dPQ0FBOnDhx3fufOnUqz/dd4SaPfH19adKkCUuXLs1wfunSpdx5550WVVX4GIbByJEjmTt3LitWrKBq1aoZnq9atSqhoaEZ7nNycjKrVq1y3ucmTZpQrFixDNccP36cXbt26Z/F/0RFRbFz505iY2OdR2RkJIMGDSI2NpZq1arpPrtAq1atrlvKYP/+/VSuXBnQ32dXunz5Ml5eGX+VeXt7O6eC6167nqvuacuWLUlISGDz5s3OazZt2kRCQkLe73uehiOLYRhpU8E//fRTY8+ePcYTTzxhFC9e3Dh8+LDVpRUajz76qBESEmLExMQYx48fdx6XL192XvPaa68ZISEhxty5c42dO3caAwcOzHLqYaVKlYxly5YZ27ZtMzp27Fikp3PmRPrZUoah++wKmzdvNnx8fIxJkyYZBw4cML7++msjMDDQmDFjhvMa3WfXGDZsmHHbbbc5p4LPnTvXKFu2rPHss886r9G9zr0LFy4Y27dvN7Zv324AxltvvWVs377ducSJq+5pt27djPr16xsbNmwwNmzYYNSrV09Twd3Jv//9b6Ny5cqGr6+v0bhxY+cUZskZIMvj888/d15jt9uNF1980QgNDTX8/PyMtm3bGjt37szwPleuXDFGjhxplC5d2ggICDDuvvtu48iRIwX8bQqXzOFG99k1fvzxR6Nu3bqGn5+fUatWLePjjz/O8Lzus2skJiYao0ePNiIiIgx/f3+jWrVqxrhx44ykpCTnNbrXubdy5cos/5s8bNgwwzBcd0/PnDljDBo0yAgKCjKCgoKMQYMGGefOnctz/TbDMIy8tf2IiIiIuA+NuRERERGPonAjIiIiHkXhRkRERDyKwo2IiIh4FIUbERER8SgKNyIiIuJRFG5ERETEoyjciIiIiEdRuBERwdyd+Pvvv7e6DBFxAYUbEbHc/fffj81mu+7o1q2b1aWJSCHkY3UBIiIA3bp14/PPP89wzs/Pz6JqRKQwU8uNiLgFPz8/QkNDMxylSpUCzC6jadOm0b17dwICAqhatSpz5szJ8PqdO3fSsWNHAgICKFOmDI888ggXL17McM1nn31GnTp18PPzIywsjJEjR2Z4/vTp0/z1r38lMDCQGjVqMH/+/Pz90iKSLxRuRKRQGD9+PP369WPHjh0MHjyYgQMHEhcXB8Dly5fp1q0bpUqV4pdffmHOnDksW7YsQ3iZNm0aI0aM4JFHHmHnzp3Mnz+f6tWrZ/iMl156iXvvvZdff/2VHj16MGjQIM6ePVug31NEXCDP+4qLiOTRsGHDDG9vb6N48eIZjpdfftkwDMMAjOHDh2d4TfPmzY1HH33UMAzD+Pjjj41SpUoZFy9edD7/008/GV5eXkZ8fLxhGIZRsWJFY9y4cTesATD++c9/Oh9fvHjRsNlsxqJFi1z2PUWkYGjMjYi4hQ4dOjBt2rQM50qXLu38c8uWLTM817JlS2JjYwGIi4ujQYMGFC9e3Pl8q1atsNvt7Nu3D5vNxrFjx4iKisq2hvr16zv/XLx4cYKCgjh58uStfiURsYjCjYi4heLFi1/XTXQzNpsNAMMwnH/O6pqAgIAcvV+xYsWue63dbs9VTSJiPY25EZFCYePGjdc9rlWrFgC1a9cmNjaWS5cuOZ9ft24dXl5e3H777QQFBVGlShWWL19eoDWLiDXUciMibiEpKYn4+PgM53x8fChbtiwAc+bMITIyktatW/P111+zefNmPv30UwAGDRrEiy++yLBhw5gwYQKnTp1i1KhRDBkyhAoVKgAwYcIEhg8fTvny5enevTsXLlxg3bp1jBo1qmC/qIjkO4UbEXELixcvJiwsLMO5mjVrsnfvXsCcyTRz5kwee+wxQkND+frrr6lduzYAgYGB/Pzzz4wePZqmTZsSGBhIv379eOutt5zvNWzYMK5evcrbb7/N008/TdmyZenfv3/BfUERKTA2wzAMq4sQEcmOzWZj3rx59OnTx+pSRKQQ0JgbERER8SgKNyIiIuJRNOZGRNyees9FJDfUciMiIiIeReFGREREPIrCjYiIiHgUhRsRERHxKAo3IiIi4lEUbkRERMSjKNyIiIiIR1G4EREREY/y/6rw9oEFNetsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 1000\n",
    "\n",
    "# Initialize a new network\n",
    "params = init_rnn(hidden_size=hidden_size, vocab_size=vocab_size)\n",
    "\n",
    "# Initialize hidden state as zeros\n",
    "hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "# Track loss\n",
    "training_loss, validation_loss = [], []\n",
    "\n",
    "# For each epoch\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    # Track loss\n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    \n",
    "     # For each sentence in validation set\n",
    "    for inputs, targets in validation_set:\n",
    "        \n",
    "        # One-hot encode input and target sequence\n",
    "        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)\n",
    "        targets_one_hot = one_hot_encode_sequence(targets, vocab_size)\n",
    "        \n",
    "        # Re-initialize hidden state\n",
    "        hidden_state = np.zeros_like(hidden_state)\n",
    "\n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE!\n",
    "        outputs, hidden_states = forward_pass(inputs_one_hot, hidden_state, params)\n",
    "\n",
    "        # Backward pass\n",
    "        # YOUR CODE HERE!\n",
    "        loss, _ = backward_pass(inputs_one_hot, outputs, hidden_states, targets_one_hot, params)\n",
    "        \n",
    "        # Update loss\n",
    "        epoch_validation_loss += loss\n",
    "    \n",
    "    # For each sentence in training set\n",
    "    for inputs, targets in training_set:\n",
    "        \n",
    "        # One-hot encode input and target sequence\n",
    "        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)\n",
    "        targets_one_hot = one_hot_encode_sequence(targets, vocab_size)\n",
    "        \n",
    "        # Re-initialize hidden state\n",
    "        hidden_state = np.zeros_like(hidden_state)\n",
    "\n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE!\n",
    "        outputs, hidden_states = forward_pass(inputs_one_hot, hidden_state, params)\n",
    "\n",
    "        # Backward pass\n",
    "        # YOUR CODE HERE!\n",
    "        loss, grads = backward_pass(inputs_one_hot, outputs, hidden_states, targets_one_hot, params)\n",
    "        \n",
    "        if np.isnan(loss):\n",
    "            raise ValueError('Gradients have vanished!')\n",
    "        \n",
    "        # Update parameters\n",
    "        params = update_parameters(params, grads, lr=3e-4)\n",
    "        \n",
    "        # Update loss\n",
    "        epoch_training_loss += loss\n",
    "        \n",
    "    # Save loss for plot\n",
    "    training_loss.append(epoch_training_loss/len(training_set))\n",
    "    validation_loss.append(epoch_validation_loss/len(validation_set))\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if i % 100 == 0:\n",
    "        print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n",
    "\n",
    "\n",
    "# Get first sentence in test set\n",
    "inputs, targets = test_set[1]\n",
    "\n",
    "# One-hot encode input and target sequence\n",
    "inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)\n",
    "targets_one_hot = one_hot_encode_sequence(targets, vocab_size)\n",
    "\n",
    "# Initialize hidden state as zeros\n",
    "hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "# Forward pass\n",
    "outputs, hidden_states = forward_pass(inputs_one_hot, hidden_state, params)\n",
    "output_sentence = [idx_to_word[np.argmax(output)] for output in outputs]\n",
    "print('Input sentence:')\n",
    "print(inputs)\n",
    "\n",
    "print('\\nTarget sequence:')\n",
    "print(targets)\n",
    "\n",
    "print('\\nPredicted sequence:')\n",
    "print([idx_to_word[np.argmax(output)] for output in outputs])\n",
    "\n",
    "# Plot training and validation loss\n",
    "epoch = np.arange(len(training_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
    "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('NLL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "['a', 'a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'b', 'b']\n"
     ]
    }
   ],
   "source": [
    "def freestyle(params, sentence='', num_generate=4):\n",
    "    \"\"\"\n",
    "    Takes in a sentence as a string and outputs a sequence\n",
    "    based on the predictions of the RNN.\n",
    "    \n",
    "    Args:\n",
    "     `params`: the parameters of the network\n",
    "     `sentence`: string with whitespace-separated tokens\n",
    "     `num_generate`: the number of tokens to generate\n",
    "    \"\"\"\n",
    "    sentence = sentence.split(' ')\n",
    "    \n",
    "    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)\n",
    "    \n",
    "    # Initialize hidden state as zeros\n",
    "    hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Generate hidden state for sentence\n",
    "    outputs, hidden_states = forward_pass(sentence_one_hot, hidden_state, params)\n",
    "    \n",
    "    # Output sentence\n",
    "    output_sentence = sentence\n",
    "    \n",
    "    # Append first prediction\n",
    "    word = idx_to_word[np.argmax(outputs[-1])]    \n",
    "    output_sentence.append(word)\n",
    "    \n",
    "    # Forward pass\n",
    "    for i in range(num_generate):\n",
    "\n",
    "        # Get the latest prediction and latest hidden state\n",
    "        output = outputs[-1]\n",
    "        hidden_state = hidden_states[-1]\n",
    "    \n",
    "        # Reshape our output to match the input shape of our forward pass\n",
    "        output = output.reshape(1, output.shape[0], output.shape[1])\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs, hidden_states = forward_pass(output, hidden_state, params)\n",
    "        \n",
    "        # Compute the index the most likely word and look up the corresponding word\n",
    "        word = idx_to_word[np.argmax(outputs)]\n",
    "        \n",
    "        output_sentence.append(word)\n",
    "        \n",
    "    return output_sentence\n",
    "    \n",
    "# Perform freestyle\n",
    "print('Example:')\n",
    "print(freestyle(params, sentence='a a a a a b'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
